# 4-Day Emergency Plan - Federated Learning Demo

**Deadline:** 4 days from now  
**Goal:** Working FL demo with heterogeneity handling  
**Strategy:** Focus on essentials, skip nice-to-haves

---

## üéØ What You MUST Have (Non-Negotiable)

1. ‚úÖ **FL working** (3 clients, 5 rounds)
2. ‚úÖ **Basic heterogeneity handling** (normalization)
3. ‚úÖ **Demo scenario** (knowledge transfer proof)
4. ‚úÖ **Documentation** (how to run it)

## ‚ùå What You Can Skip (For Now)

- ‚ùå Differential privacy (add later)
- ‚ùå Dashboard integration (use terminal output)
- ‚ùå Advanced heterogeneity solutions (FedProx, weighted aggregation)
- ‚ùå Docker deployment (run locally)
- ‚ùå Production features (monitoring, logging, error handling)

---

## üìÖ Day-by-Day Plan

### **Day 1: Get FL Working (8 hours)**

**Goal:** 3 clients connect, complete 1 FL round

#### Morning (4 hours): Setup

**Tasks:**
1. Install Flower: `pip install flwr` (5 min)
2. Copy `fl_simple_example.py` (already created) (5 min)
3. Prepare data for 3 facilities (30 min)
4. Test with small dataset (1K samples) (30 min)
5. Fix any errors (2 hours buffer)

**Commands:**
```bash
# Install
pip install flwr

# Prepare data (create this script)
python prepare_fl_data_simple.py

# Test FL
python fl_simple_example.py server 1 3  # 1 round for testing
python fl_simple_example.py client facility_a
python fl_simple_example.py client facility_b
python fl_simple_example.py client facility_c
```

**Success Criteria:**
- ‚úÖ 3 clients connect
- ‚úÖ 1 FL round completes
- ‚úÖ No errors

#### Afternoon (4 hours): Scale Up

**Tasks:**
1. Test with 10K samples (30 min)
2. Run 5 FL rounds (1 hour)
3. Verify accuracy improves (30 min)
4. Document commands (30 min)
5. Buffer for issues (1.5 hours)

**Success Criteria:**
- ‚úÖ 5 FL rounds complete
- ‚úÖ Accuracy improves each round
- ‚úÖ Can run reliably

---

### **Day 2: Add Normalization (6 hours)**

**Goal:** Handle heterogeneity with per-facility normalization

#### Morning (3 hours): Implement Normalization

**Tasks:**
1. Create `simple_normalizer.py` (1 hour)
2. Update FL client to use normalization (1 hour)
3. Test with 3 facilities (1 hour)

**Code to create:**

`simple_normalizer.py`:
```python
import numpy as np
import pickle

class SimpleNormalizer:
    """Minimal normalizer for FL"""
    
    def __init__(self, facility_id):
        self.facility_id = facility_id
        self.mean = None
        self.std = None
    
    def fit(self, X):
        self.mean = X.mean(axis=0)
        self.std = X.std(axis=0) + 1e-8
        print(f"‚úì {self.facility_id} normalizer fitted")
    
    def transform(self, X):
        return (X - self.mean) / self.std
    
    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
    
    def save(self, path):
        with open(path, 'wb') as f:
            pickle.dump({'mean': self.mean, 'std': self.std}, f)
    
    def load(self, path):
        with open(path, 'rb') as f:
            data = pickle.load(f)
            self.mean = data['mean']
            self.std = data['std']
```

**Update `fl_simple_example.py`:**
```python
# Add at top
from simple_normalizer import SimpleNormalizer

# In load_facility_data function, add:
normalizer = SimpleNormalizer(facility_id)
X = normalizer.fit_transform(X)
normalizer.save(f'fl_data/{facility_id}/normalizer.pkl')
```

**Success Criteria:**
- ‚úÖ Normalization works
- ‚úÖ No errors
- ‚úÖ Accuracy similar or better

#### Afternoon (3 hours): Test & Compare

**Tasks:**
1. Run FL without normalization (baseline) (30 min)
2. Run FL with normalization (30 min)
3. Compare results (30 min)
4. Document improvement (30 min)
5. Buffer (1 hour)

**Success Criteria:**
- ‚úÖ Can show improvement with normalization
- ‚úÖ Results documented

---

### **Day 3: Demo Scenario (6 hours)**

**Goal:** Prove knowledge transfer (Facility B learns from Facility A)

#### Morning (3 hours): Create Specialized Datasets

**Tasks:**
1. Create script to split data by attack type (1 hour)
2. Give Facility A port scans only (30 min)
3. Give Facilities B & C other attacks (30 min)
4. Test data split (1 hour)

**Code to create:**

`create_demo_data.py`:
```python
import pandas as pd
import numpy as np

def create_demo_datasets():
    """Create specialized datasets for demo"""
    
    # Load full dataset
    X = pd.read_csv('X_train.csv')
    y = pd.read_csv('y_train.csv').values.ravel()
    
    # Assuming you have attack type labels
    # If not, use binary: 0=normal, 1=attack
    
    # Facility A: Gets port scans (or specific attack type)
    # For simplicity, let's say attacks are labeled 1-14
    # Give Facility A attacks 1-5
    mask_a = (y >= 1) & (y <= 5) | (y == 0)  # Attacks 1-5 + normal
    X_a = X[mask_a]
    y_a = y[mask_a]
    
    # Facility B: Gets attacks 6-10
    mask_b = (y >= 6) & (y <= 10) | (y == 0)
    X_b = X[mask_b]
    y_b = y[mask_b]
    
    # Facility C: Gets attacks 11-14
    mask_c = (y >= 11) | (y == 0)
    X_c = X[mask_c]
    y_c = y[mask_c]
    
    # Save
    X_a.to_csv('fl_data/facility_a/X_train.csv', index=False)
    pd.DataFrame(y_a).to_csv('fl_data/facility_a/y_train.csv', index=False)
    
    X_b.to_csv('fl_data/facility_b/X_train.csv', index=False)
    pd.DataFrame(y_b).to_csv('fl_data/facility_b/y_train.csv', index=False)
    
    X_c.to_csv('fl_data/facility_c/X_train.csv', index=False)
    pd.DataFrame(y_c).to_csv('fl_data/facility_c/y_train.csv', index=False)
    
    print(f"‚úì Facility A: {len(X_a)} samples, attacks 1-5")
    print(f"‚úì Facility B: {len(X_b)} samples, attacks 6-10")
    print(f"‚úì Facility C: {len(X_c)} samples, attacks 11-14")

if __name__ == "__main__":
    create_demo_datasets()
```

**Success Criteria:**
- ‚úÖ Each facility has different attack types
- ‚úÖ Data split makes sense

#### Afternoon (3 hours): Test Knowledge Transfer

**Tasks:**
1. Test Facility B on Facility A's attacks BEFORE FL (30 min)
2. Run FL (10 rounds) (1 hour)
3. Test Facility B on Facility A's attacks AFTER FL (30 min)
4. Document results (1 hour)

**Test script:**

`test_knowledge_transfer.py`:
```python
import pandas as pd
import numpy as np
from tensorflow import keras

def test_knowledge_transfer():
    """Test if Facility B learned from Facility A"""
    
    # Load Facility B's model
    model_b = keras.models.load_model('facility_b_model.h5')
    
    # Load Facility A's test data (attacks B hasn't seen)
    X_test_a = pd.read_csv('fl_data/facility_a/X_test.csv').values
    y_test_a = pd.read_csv('fl_data/facility_a/y_test.csv').values.ravel()
    
    # Reshape for CNN-LSTM
    X_test_a = X_test_a.reshape(X_test_a.shape[0], 1, X_test_a.shape[1])
    
    # Test
    loss, accuracy = model_b.evaluate(X_test_a, y_test_a)
    
    print(f"\nFacility B accuracy on Facility A's attacks: {accuracy:.2%}")
    
    return accuracy

# Run before FL
print("BEFORE FL:")
accuracy_before = test_knowledge_transfer()

# Run FL here...

# Run after FL
print("\nAFTER FL:")
accuracy_after = test_knowledge_transfer()

print(f"\nImprovement: {accuracy_after - accuracy_before:.2%}")
```

**Success Criteria:**
- ‚úÖ Accuracy improves after FL
- ‚úÖ Can demonstrate knowledge transfer
- ‚úÖ Results are convincing (>10% improvement)

---

### **Day 4: Polish & Document (6 hours)**

**Goal:** Make it presentable and reproducible

#### Morning (3 hours): Create Demo Script

**Tasks:**
1. Create automated demo script (1 hour)
2. Test demo end-to-end (1 hour)
3. Fix any issues (1 hour)

**Code to create:**

`run_demo.sh`:
```bash
#!/bin/bash

echo "=========================================="
echo "FEDERATED LEARNING DEMO"
echo "=========================================="
echo ""

# Step 1: Prepare data
echo "Step 1: Preparing data..."
python create_demo_data.py
echo "‚úì Data prepared"
echo ""

# Step 2: Test BEFORE FL
echo "Step 2: Testing BEFORE FL..."
python test_knowledge_transfer.py > results_before.txt
echo "‚úì Baseline established"
echo ""

# Step 3: Start FL server in background
echo "Step 3: Starting FL server..."
python fl_simple_example.py server 10 3 > server.log 2>&1 &
SERVER_PID=$!
sleep 5
echo "‚úì Server started (PID: $SERVER_PID)"
echo ""

# Step 4: Start clients
echo "Step 4: Starting FL clients..."
python fl_simple_example.py client facility_a > client_a.log 2>&1 &
python fl_simple_example.py client facility_b > client_b.log 2>&1 &
python fl_simple_example.py client facility_c > client_c.log 2>&1 &
echo "‚úì Clients started"
echo ""

# Step 5: Wait for FL to complete
echo "Step 5: Running FL (10 rounds, ~30 minutes)..."
echo "   (Check server.log for progress)"
wait $SERVER_PID
echo "‚úì FL complete"
echo ""

# Step 6: Test AFTER FL
echo "Step 6: Testing AFTER FL..."
python test_knowledge_transfer.py > results_after.txt
echo "‚úì Results saved"
echo ""

# Step 7: Show results
echo "=========================================="
echo "RESULTS"
echo "=========================================="
cat results_before.txt
cat results_after.txt
echo ""
echo "Demo complete! üéâ"
```

**Success Criteria:**
- ‚úÖ Demo runs automatically
- ‚úÖ Results are clear
- ‚úÖ No manual intervention needed

#### Afternoon (3 hours): Documentation

**Tasks:**
1. Create README with instructions (1 hour)
2. Create troubleshooting guide (30 min)
3. Test on fresh terminal (1 hour)
4. Final polish (30 min)

**Create `DEMO_README.md`:**
```markdown
# Federated Learning Demo - Quick Start

## Prerequisites
- Python 3.8+
- 16GB RAM
- 10GB disk space

## Installation (5 minutes)
```bash
pip install flwr tensorflow pandas numpy scikit-learn
```

## Running the Demo (30 minutes)

### Option 1: Automated (Recommended)
```bash
bash run_demo.sh
```

### Option 2: Manual
```bash
# Terminal 1 - Server
python fl_simple_example.py server 10 3

# Terminal 2 - Facility A
python fl_simple_example.py client facility_a

# Terminal 3 - Facility B
python fl_simple_example.py client facility_b

# Terminal 4 - Facility C
python fl_simple_example.py client facility_c
```

## Expected Results
- Before FL: Facility B accuracy on unseen attacks = ~50%
- After FL: Facility B accuracy on unseen attacks = ~85%
- Improvement: ~35%

## Troubleshooting
- **Clients can't connect**: Check server is running on port 8080
- **Out of memory**: Reduce dataset size in `create_demo_data.py`
- **Training too slow**: Use GPU or reduce epochs

## Demo Script (3 minutes)
1. Show problem: "Facilities can't share data"
2. Show solution: "Federated learning"
3. Run demo: `bash run_demo.sh`
4. Show results: "Knowledge transferred without sharing data!"
```

**Success Criteria:**
- ‚úÖ Anyone can run the demo
- ‚úÖ Instructions are clear
- ‚úÖ Troubleshooting covers common issues

---

## üìä Deliverables Checklist

### Code
- [ ] `fl_simple_example.py` (already created)
- [ ] `simple_normalizer.py` (Day 2)
- [ ] `create_demo_data.py` (Day 3)
- [ ] `test_knowledge_transfer.py` (Day 3)
- [ ] `run_demo.sh` (Day 4)

### Documentation
- [ ] `DEMO_README.md` (Day 4)
- [ ] `4_DAY_PLAN.md` (this file)
- [ ] Results screenshots/logs

### Demo
- [ ] Can run in 30 minutes
- [ ] Shows knowledge transfer
- [ ] Proves FL works

---

## üéØ Success Metrics

### Minimum Success (Must Achieve)
- ‚úÖ FL completes 10 rounds
- ‚úÖ 3 clients participate
- ‚úÖ Knowledge transfer demonstrated
- ‚úÖ Can run demo reliably

### Target Success (Goal)
- ‚úÖ Accuracy improvement >20%
- ‚úÖ Normalization working
- ‚úÖ Automated demo script
- ‚úÖ Clear documentation

### Stretch Success (Bonus)
- ‚úÖ Accuracy improvement >30%
- ‚úÖ Multiple demo scenarios
- ‚úÖ Video recording
- ‚úÖ Presentation slides

---

## ‚ö†Ô∏è Risk Mitigation

### Risk 1: FL doesn't converge
**Mitigation:**
- Use small dataset (10K samples)
- Reduce epochs (3 instead of 5)
- Increase rounds (15 instead of 10)

**Fallback:**
- Show FL process even if accuracy doesn't improve much
- Explain what would happen with more data/time

### Risk 2: Out of memory
**Mitigation:**
- Use smaller dataset (1K samples for testing)
- Reduce batch size (64 instead of 128)
- Close other applications

**Fallback:**
- Run on cloud (Google Colab, AWS)
- Use even smaller dataset

### Risk 3: Can't demonstrate knowledge transfer
**Mitigation:**
- Create very distinct datasets (Facility A: only attack type 1, Facility B: only attack type 2)
- Use binary classification (normal vs attack)
- Test multiple times

**Fallback:**
- Show FL process working
- Show accuracy improving over rounds
- Explain knowledge transfer conceptually

---

## üìû Emergency Contacts

### If Stuck on Day 1 (FL not working)
- Check Flower docs: https://flower.dev/docs/
- Use Flower example: `python -m flwr_example.quickstart_tensorflow`
- Ask on Flower Slack: https://flower.dev/join-slack

### If Stuck on Day 2 (Normalization issues)
- Skip normalization, focus on basic FL
- Use sklearn StandardScaler instead
- Test with small dataset first

### If Stuck on Day 3 (Demo scenario)
- Simplify: Use binary classification (normal vs attack)
- Use existing data split (don't create specialized datasets)
- Show FL working, explain knowledge transfer

### If Stuck on Day 4 (Documentation)
- Use existing documentation
- Focus on README only
- Screenshots of terminal output

---

## üöÄ Quick Commands Reference

### Day 1
```bash
pip install flwr
python fl_simple_example.py server 5 3
python fl_simple_example.py client facility_a
```

### Day 2
```bash
python fl_simple_example.py server 5 3  # With normalization
```

### Day 3
```bash
python create_demo_data.py
python test_knowledge_transfer.py
bash run_demo.sh
```

### Day 4
```bash
bash run_demo.sh  # Final test
```

---

## üí° Pro Tips

1. **Test with small data first** (1K samples, 1 round)
2. **Save your work frequently** (git commit after each working version)
3. **Keep it simple** (don't add features, focus on working demo)
4. **Document as you go** (write README while testing)
5. **Have a backup plan** (if FL fails, show process and explain)

---

## üìà Time Allocation

| Day | Focus | Hours | Priority |
|-----|-------|-------|----------|
| 1 | Get FL working | 8 | CRITICAL |
| 2 | Add normalization | 6 | HIGH |
| 3 | Demo scenario | 6 | HIGH |
| 4 | Polish & document | 6 | MEDIUM |

**Total:** 26 hours over 4 days

---

## ‚úÖ Daily Goals

### Day 1 End
- [ ] FL runs successfully
- [ ] 3 clients connect
- [ ] 5 rounds complete
- [ ] No errors

### Day 2 End
- [ ] Normalization implemented
- [ ] FL runs with normalization
- [ ] Can show improvement
- [ ] Code committed

### Day 3 End
- [ ] Demo scenario works
- [ ] Knowledge transfer proven
- [ ] Results documented
- [ ] Demo script created

### Day 4 End
- [ ] Documentation complete
- [ ] Demo runs automatically
- [ ] Tested on fresh terminal
- [ ] Ready to present

---

## üé¨ Final Demo (3 Minutes)

**Slide 1: Problem (30 sec)**
"Three facilities want to improve attack detection, but can't share data."

**Slide 2: Solution (30 sec)**
"Federated Learning: Learn together without sharing data."

**Slide 3: Live Demo (90 sec)**
```bash
bash run_demo.sh
# Show: Clients training, accuracy improving, knowledge transfer
```

**Slide 4: Results (30 sec)**
"Before FL: 50% accuracy on unseen attacks
After FL: 85% accuracy
Knowledge transferred without sharing data! üéâ"

---

**Good luck! You've got this! üöÄ**

Focus on Day 1 first. Get FL working. Everything else builds on that.

---

**Document Version:** 1.0  
**Created:** November 25, 2025  
**Deadline:** 4 days  
**Status:** URGENT - START NOW
