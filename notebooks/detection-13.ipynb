{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NNX6hhJuIPAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8720033-e526-4f4b-c641-6bf457f1137f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3687968223.py:7: DtypeWarning: Columns (2,3,6,11,13,14,15,16,17,31,32,34,39,45,51,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/DNN-EdgeIIoT-dataset.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: (2219201, 63)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/DNN-EdgeIIoT-dataset.csv')\n",
        "\n",
        "print(f\"Dataset loaded: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The labels are already in the dataset\n",
        "print(\"Dataset columns:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# The last column should be the label column\n",
        "print(\"\\nLabel column name:\", df.columns[-1])\n",
        "print(\"Label distribution:\")\n",
        "print(df.iloc[:, -1].value_counts())\n",
        "\n",
        "# Use cleaned dataframe directly\n",
        "df_with_labels = df.copy()\n",
        "print(\"\\nDataset with labels shape:\", df_with_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqMmett_MRip",
        "outputId": "594f876c-13ac-4ac7-c553-e8a4501d385c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns:\n",
            "['frame.time', 'ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4', 'arp.opcode', 'arp.hw.size', 'arp.src.proto_ipv4', 'icmp.checksum', 'icmp.seq_le', 'icmp.transmit_timestamp', 'icmp.unused', 'http.file_data', 'http.content_length', 'http.request.uri.query', 'http.request.method', 'http.referer', 'http.request.full_uri', 'http.request.version', 'http.response', 'http.tls_port', 'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.options', 'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu', 'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in', 'mqtt.conack.flags', 'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.protoname', 'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver', 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id', 'Attack_label', 'Attack_type']\n",
            "\n",
            "Label column name: Attack_type\n",
            "Label distribution:\n",
            "Attack_type\n",
            "Normal                   1615643\n",
            "DDoS_UDP                  121568\n",
            "DDoS_ICMP                 116436\n",
            "SQL_injection              51203\n",
            "Password                   50153\n",
            "Vulnerability_scanner      50110\n",
            "DDoS_TCP                   50062\n",
            "DDoS_HTTP                  49911\n",
            "Uploading                  37634\n",
            "Backdoor                   24862\n",
            "Port_Scanning              22564\n",
            "XSS                        15915\n",
            "Ransomware                 10925\n",
            "MITM                        1214\n",
            "Fingerprinting              1001\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset with labels shape: (2219201, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_types_to_move = [\n",
        "    \"MITM\",\n",
        "    \"Fingerprinting\",\n",
        "    \"Ransomware\",\n",
        "    \"XSS\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "Xg_L8zA4N6yF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rows that match the chosen attack types\n",
        "df_moved = df[df[\"Attack_type\"].isin(attack_types_to_move)]\n",
        "\n",
        "# Remaining dataset (everything else)\n",
        "df_remaining = df[~df[\"Attack_type\"].isin(attack_types_to_move)]\n",
        "\n",
        "print(\"Moved subset shape:\", df_moved.shape)\n",
        "print(\"Remaining dataset shape:\", df_remaining.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAJFHEnJOBBn",
        "outputId": "c5ef02b1-67fd-4891-f4c1-69b2a41c979a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved subset shape: (29055, 63)\n",
            "Remaining dataset shape: (2190146, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRemaining label distribution:\")\n",
        "print(df_remaining[\"Attack_type\"].value_counts())\n",
        "\n",
        "print(\"\\nMoved subset label distribution:\")\n",
        "print(df_moved[\"Attack_type\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoC-i-ocOFp_",
        "outputId": "51934c97-ca01-45b4-e248-afbef5b3b9bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Remaining label distribution:\n",
            "Attack_type\n",
            "Normal                   1615643\n",
            "DDoS_UDP                  121568\n",
            "DDoS_ICMP                 116436\n",
            "SQL_injection              51203\n",
            "Password                   50153\n",
            "Vulnerability_scanner      50110\n",
            "DDoS_TCP                   50062\n",
            "DDoS_HTTP                  49911\n",
            "Uploading                  37634\n",
            "Backdoor                   24862\n",
            "Port_Scanning              22564\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Moved subset label distribution:\n",
            "Attack_type\n",
            "XSS               15915\n",
            "Ransomware        10925\n",
            "MITM               1214\n",
            "Fingerprinting     1001\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_remaining_path = \"/content/drive/MyDrive/DNN-EdgeIIoT-main_filtered.csv\"\n",
        "output_moved_path = \"/content/drive/MyDrive/DNN-EdgeIIoT-moved_attacks.csv\"\n",
        "\n",
        "df_remaining.to_csv(output_remaining_path, index=False)\n",
        "df_moved.to_csv(output_moved_path, index=False)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" → Remaining:\", output_remaining_path)\n",
        "print(\" → Moved:\", output_moved_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDy7sZvWOHNY",
        "outputId": "38ebc1e8-c2d9-401a-dfa4-dd80c3f9b879"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            " → Remaining: /content/drive/MyDrive/DNN-EdgeIIoT-main_filtered.csv\n",
            " → Moved: /content/drive/MyDrive/DNN-EdgeIIoT-moved_attacks.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 0. Mount Google Drive\n",
        "# ============================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================\n",
        "# 1. Imports\n",
        "# ============================================================\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score,\n",
        "    precision_score, recall_score, f1_score\n",
        ")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. Paths (EDIT THESE IF NEEDED)\n",
        "# ============================================================\n",
        "\n",
        "# Path to your main filtered dataset (without the 4 removed attack types)\n",
        "DATA_PATH = \"/content/drive/MyDrive/DNN-EdgeIIoT-main_filtered.csv\"\n",
        "\n",
        "# Folder in Drive where you want to save model & artifacts\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/EdgeIIoT_filtered_model\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"DATA_PATH:\", DATA_PATH)\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
        "\n",
        "# ============================================================\n",
        "# 3. Load and basic preprocess\n",
        "# ============================================================\n",
        "print(\"\\nLoading filtered dataset...\")\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Full filtered dataset shape:\", df.shape)\n",
        "print(\"\\nAttack_type distribution:\")\n",
        "print(df[\"Attack_type\"].value_counts())\n",
        "\n",
        "# --------- Separate features and label ----------\n",
        "label_col = \"Attack_type\"\n",
        "\n",
        "y = df[label_col].values\n",
        "\n",
        "# Keep only numeric features to match CNN/LSTM expectations\n",
        "X = df.drop(columns=[label_col, \"Attack_label\"], errors=\"ignore\")\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "print(\"\\nNumeric feature matrix shape:\", X.shape)\n",
        "print(\"Columns used as features:\")\n",
        "print(list(X.columns))\n",
        "\n",
        "# ============================================================\n",
        "# 4. Train / Val / Test split\n",
        "# ============================================================\n",
        "print(\"\\nSplitting into train / val / test (60 / 20 / 20)...\")\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.25, random_state=42, stratify=y_train_full\n",
        ")  # 0.25 of 0.8 = 0.2 → 60/20/20\n",
        "\n",
        "print(f\"Train set:      {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "print(f\"Test set:       {X_test.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. Prepare data (scaling, label encoding, reshape)\n",
        "# ============================================================\n",
        "def prepare_data(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "    \"\"\"Normalize features and encode labels, reshape for CNN-LSTM.\"\"\"\n",
        "    print(\"\\nPreparing data for CNN-LSTM...\")\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_val_encoded = label_encoder.transform(y_val)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "    print(\"Classes:\", label_encoder.classes_)\n",
        "\n",
        "    # Reshape for CNN-LSTM: (samples, timesteps, features)\n",
        "    n_features = X_train_scaled.shape[1]\n",
        "    timesteps = 1\n",
        "\n",
        "    X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], timesteps, n_features)\n",
        "    X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], timesteps, n_features)\n",
        "    X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], timesteps, n_features)\n",
        "\n",
        "    print(\"\\nReshaped data:\")\n",
        "    print(\"X_train:\", X_train_reshaped.shape)\n",
        "    print(\"X_val:  \", X_val_reshaped.shape)\n",
        "    print(\"X_test: \", X_test_reshaped.shape)\n",
        "\n",
        "    return (\n",
        "        X_train_reshaped, X_val_reshaped, X_test_reshaped,\n",
        "        y_train_encoded, y_val_encoded, y_test_encoded,\n",
        "        scaler, label_encoder, num_classes\n",
        "    )\n",
        "\n",
        "X_train_prep, X_val_prep, X_test_prep, y_train_enc, y_val_enc, y_test_enc, scaler, label_encoder, num_classes = prepare_data(\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 6. Model definitions (same as your original)\n",
        "# ============================================================\n",
        "def build_multiclass_cnn_lstm(input_shape, num_classes):\n",
        "    \"\"\"Build CNN-LSTM model for multiclass classification.\"\"\"\n",
        "    model = models.Sequential([\n",
        "        # CNN Layers for feature extraction\n",
        "        layers.Conv1D(filters=64, kernel_size=3, activation='relu',\n",
        "                      input_shape=input_shape, padding='same', name='conv1d_1'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(pool_size=1),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv1D(filters=128, kernel_size=3, activation='relu',\n",
        "                      padding='same', name='conv1d_2'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(pool_size=1),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv1D(filters=256, kernel_size=3, activation='relu',\n",
        "                      padding='same', name='conv1d_3'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(pool_size=1),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        # LSTM Layers for temporal dependencies\n",
        "        layers.LSTM(128, return_sequences=True, name='lstm_1'),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.LSTM(64, return_sequences=False, name='lstm_2'),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        # Dense Layers for classification\n",
        "        layers.Dense(128, activation='relu', name='dense_1'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Dense(64, activation='relu', name='dense_2'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        # Output layer for multiclass classification\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def compile_and_train_multiclass(model, X_train, y_train, X_val, y_val,\n",
        "                                 epochs=50, batch_size=128, ckpt_path=None):\n",
        "    \"\"\"Compile and train multiclass classification model.\"\"\"\n",
        "    print(\"\\nCompiling multiclass classification model...\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\nModel Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    if ckpt_path is None:\n",
        "        ckpt_path = os.path.join(OUTPUT_DIR, \"best_multiclass_cnn_lstm_model.h5\")\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        ckpt_path,\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\nTraining multiclass classification model...\")\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, label_encoder):\n",
        "    \"\"\"Evaluate model performance.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MODEL EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_proba = model.predict(X_test, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nAccuracy:  {accuracy*100:.2f}%\")\n",
        "    print(f\"Precision: {precision*100:.2f}%\")\n",
        "    print(f\"Recall:    {recall*100:.2f}%\")\n",
        "    print(f\"F1-Score:  {f1*100:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CLASSIFICATION REPORT\")\n",
        "    print(\"=\"*70)\n",
        "    print(classification_report(\n",
        "        y_test, y_pred,\n",
        "        target_names=label_encoder.classes_,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    return accuracy, precision, recall, f1, cm, y_pred\n",
        "\n",
        "\n",
        "def plot_training_history(history, save_path):\n",
        "    \"\"\"Plot training and validation metrics.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Loss\n",
        "    axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\nTraining history plot saved: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, save_path):\n",
        "    \"\"\"Plot confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels,\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Confusion matrix plot saved: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# 7. Main: train on MAIN FILTERED DATASET and save to Drive\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MULTICLASS CLASSIFICATION ON MAIN FILTERED ATTACKS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "input_shape = (X_train_prep.shape[1], X_train_prep.shape[2])\n",
        "model = build_multiclass_cnn_lstm(input_shape, num_classes)\n",
        "\n",
        "ckpt_file = os.path.join(OUTPUT_DIR, \"best_multiclass_cnn_lstm_model.h5\")\n",
        "\n",
        "model, history = compile_and_train_multiclass(\n",
        "    model,\n",
        "    X_train_prep, y_train_enc,\n",
        "    X_val_prep, y_val_enc,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    ckpt_path=ckpt_file\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "accuracy, precision, recall, f1, cm, y_pred = evaluate_model(\n",
        "    model, X_test_prep, y_test_enc, label_encoder\n",
        ")\n",
        "\n",
        "# Plots\n",
        "history_plot_path = os.path.join(OUTPUT_DIR, \"multiclass_training_history.png\")\n",
        "cm_plot_path = os.path.join(OUTPUT_DIR, \"multiclass_confusion_matrix.png\")\n",
        "\n",
        "plot_training_history(history, history_plot_path)\n",
        "plot_confusion_matrix(cm, label_encoder.classes_, cm_plot_path)\n",
        "\n",
        "# ============================================================\n",
        "# 8. Save model + artifacts to Drive\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING MODEL AND RESULTS TO GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save final model (Keras format)\n",
        "final_model_path = os.path.join(OUTPUT_DIR, \"cnn_lstm_filtered_final_model.keras\")\n",
        "model.save(final_model_path)\n",
        "print(\"Model saved:\", final_model_path)\n",
        "\n",
        "# Save label encoder\n",
        "le_path = os.path.join(OUTPUT_DIR, \"label_encoder_filtered.pkl\")\n",
        "with open(le_path, 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(\"Label encoder saved:\", le_path)\n",
        "\n",
        "# Save scaler\n",
        "scaler_path = os.path.join(OUTPUT_DIR, \"scaler_filtered.pkl\")\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"Scaler saved:\", scaler_path)\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'accuracy': accuracy,\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1_score': f1,\n",
        "    'num_classes': num_classes,\n",
        "    'classes': label_encoder.classes_,\n",
        "    'confusion_matrix': cm\n",
        "}\n",
        "results_path = os.path.join(OUTPUT_DIR, \"model_results_filtered.pkl\")\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "print(\"Results saved:\", results_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING ON FILTERED DATASET COMPLETE!\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FJOvZL-XSI_y",
        "outputId": "06b07206-4f10-40fd-cc4b-23eb7377ba82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TensorFlow version: 2.19.0\n",
            "Keras version: 3.10.0\n",
            "DATA_PATH: /content/drive/MyDrive/DNN-EdgeIIoT-main_filtered.csv\n",
            "OUTPUT_DIR: /content/drive/MyDrive/EdgeIIoT_filtered_model\n",
            "\n",
            "Loading filtered dataset...\n",
            "Full filtered dataset shape: (2190146, 63)\n",
            "\n",
            "Attack_type distribution:\n",
            "Attack_type\n",
            "Normal                   1615643\n",
            "DDoS_UDP                  121568\n",
            "DDoS_ICMP                 116436\n",
            "SQL_injection              51203\n",
            "Password                   50153\n",
            "Vulnerability_scanner      50110\n",
            "DDoS_TCP                   50062\n",
            "DDoS_HTTP                  49911\n",
            "Uploading                  37634\n",
            "Backdoor                   24862\n",
            "Port_Scanning              22564\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Numeric feature matrix shape: (2190146, 43)\n",
            "Columns used as features:\n",
            "['arp.opcode', 'arp.hw.size', 'icmp.checksum', 'icmp.seq_le', 'icmp.transmit_timestamp', 'icmp.unused', 'http.content_length', 'http.response', 'http.tls_port', 'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.qu', 'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in', 'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.topic_len', 'mqtt.ver', 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id']\n",
            "\n",
            "Splitting into train / val / test (60 / 20 / 20)...\n",
            "Train set:      (1314087, 43)\n",
            "Validation set: (438029, 43)\n",
            "Test set:       (438030, 43)\n",
            "\n",
            "Preparing data for CNN-LSTM...\n",
            "Number of classes: 11\n",
            "Classes: ['Backdoor' 'DDoS_HTTP' 'DDoS_ICMP' 'DDoS_TCP' 'DDoS_UDP' 'Normal'\n",
            " 'Password' 'Port_Scanning' 'SQL_injection' 'Uploading'\n",
            " 'Vulnerability_scanner']\n",
            "\n",
            "Reshaped data:\n",
            "X_train: (1314087, 1, 43)\n",
            "X_val:   (438029, 1, 43)\n",
            "X_test:  (438030, 1, 43)\n",
            "\n",
            "======================================================================\n",
            "MULTICLASS CLASSIFICATION ON MAIN FILTERED ATTACKS\n",
            "======================================================================\n",
            "\n",
            "Compiling multiclass classification model...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m197,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m715\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m397,963\u001b[0m (1.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,963</span> (1.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m396,683\u001b[0m (1.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,683</span> (1.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training multiclass classification model...\n",
            "Epoch 1/50\n",
            "\u001b[1m 7365/10267\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 15ms/step - accuracy: 0.8911 - loss: 0.3898"
          ]
        }
      ]
    }
  ]
}